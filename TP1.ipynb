{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático I\n",
    "Alunas: Cecília Kind e Selene Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo:\n",
    "O programa a seguir realiza a compressão de uma imagem a partir Codificação Preditiva sem perdas seguida da codificação de Huffman. O trabalho é divido em algumas etapas que serão abordadas passo a passo:\n",
    "\n",
    "- 1: Obtenção e especificaçao da imagem orginal\n",
    "- 2: Aplicação da codificação preditiva sem perda\n",
    "- 3: Aplicação da codificação de Huffman\n",
    "- 4: Armazenamaneto da imagem\n",
    "- 5: Recuperação da imagem armazenada\n",
    "- 6: Decodificação do código de Huffman\n",
    "- 7: Recuperação da imagem a partir da matriz de erro\n",
    "- 8: Análise final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas utilizadas:\n",
    "Obs: a estrutura BitArray foi importada da biblioteca bitstring, que pode ser instalada com o comando comentado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "from typing import NamedTuple, List\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#!pip install --user bitstring\n",
    "from bitstring import BitArray\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções e estruturas utilizadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entropia, RMSE e impressão da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_imagem(imagem, titulo):\n",
    "    plt.title(titulo)\n",
    "    plt.imshow(imagem, cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "def calcula_entropia(imagem):\n",
    "    freq = dict(sum(map(Counter, imagem), Counter()))\n",
    "    prob = [freq[k]/(height* width) for k in freq]   \n",
    "    entropia = 0\n",
    "    for k in prob:\n",
    "        if k != 0:\n",
    "            entropia = entropia + k*np.log2(k)\n",
    "    return -entropia\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Codificação e decodificação preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicao_erro(imagem, height, width):\n",
    "    size = height, width\n",
    "    img_pred_erro = [[0 for c in range(size[1])] for r in range(size[0])]\n",
    "\n",
    "    for row in range(0,height):\n",
    "        img_pred_erro[row][0] = int(img_original[row][0])\n",
    "\n",
    "    for row in range(0,height):\n",
    "      for col in range(1, width):\n",
    "        img_pred_erro[row][col] = int(img_original[row][col]) - int(img_original[row][col-1])\n",
    "    \n",
    "    return img_pred_erro\n",
    "\n",
    "def recupera_erro(img_decomp, height, width ):\n",
    "    for row in range(0,height):\n",
    "        for col in range(1, width):\n",
    "            img_decomp[row][col] = int(img_decomp[row][col]) + int(img_decomp[row][col-1])\n",
    "    return img_decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Codificação e decodificação de Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymCode(NamedTuple):\n",
    "    old: int\n",
    "    new: str\n",
    "\n",
    "class ProbSymCodes(NamedTuple):\n",
    "    prob: float\n",
    "    codes: List[SymCode]\n",
    "\n",
    "def codif_Huffman(imagem, height, width):\n",
    "    # calculando as frequencias\n",
    "    frequencia = dict(sum(map(Counter, imagem), Counter()))\n",
    "    lista_codigos = [ProbSymCodes(prob = frequencia[k]/(height* width), codes = [SymCode(k, \"\")]) for k in frequencia]\n",
    "    lista_codigos = sorted(lista_codigos)\n",
    "    \n",
    "    while(len (lista_codigos) > 1):\n",
    "\n",
    "        if type(lista_codigos[-1]) == ProbSymCodes: lo = lista_codigos.pop(0)\n",
    "        if type(lista_codigos[-1]) == ProbSymCodes: hi = lista_codigos.pop(0)\n",
    "\n",
    "        for idx, code in enumerate(lo.codes):\n",
    "            lo.codes[idx] = lo.codes[idx]._replace(new='0'+ lo.codes[idx].new)\n",
    "\n",
    "        for idx, code in enumerate(hi.codes):\n",
    "            hi.codes[idx] = hi.codes[idx]._replace(new='1'+ hi.codes[idx].new)\n",
    "\n",
    "        lista_codigos.insert(0, ProbSymCodes(prob = lo.prob + hi.prob, codes = lo.codes + hi.codes))\n",
    "        lista_codigos = sorted(lista_codigos)\n",
    "\n",
    "    return dict((code.old, code.new) for code in lista_codigos[-1][-1])\n",
    "\n",
    "def decod_Huffman(img_bitstr, cod_dic, height, width):\n",
    "    \n",
    "    i = 0\n",
    "    j = 1\n",
    "\n",
    "    size = height, width\n",
    "    img_decomp = np.zeros(size)\n",
    "\n",
    "    for row in range(0,height):\n",
    "        for col in range(0,width):\n",
    "            while img_bitstr[i:j] not in cod_dic:\n",
    "                j += 1        \n",
    "            img_decomp[row][col] = cod_dic[img_bitstr[i:j]]\n",
    "            i = j\n",
    "            j += 1\n",
    "            \n",
    "    return img_decomp\n",
    "\n",
    "def eficiencia_Huffman(resultado_cod, entropia, height, width):\n",
    "    return entropia/(len(resultado_cod)/(height*width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Armazenamaneto e recuperação da nova imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armazena_imagem(imagem, dicionario_codigos, matriz_codigos):\n",
    "    # WxH\n",
    "    img_size = struct.pack('!2I', imagem.shape[1], imagem.shape[0])\n",
    "    with open('compressed.txt', 'wb') as comp:\n",
    "        comp.write(img_size)\n",
    "\n",
    "        # dicionario\n",
    "        dict_bin = json.dumps(dicionario_codigos).encode('utf-8')\n",
    "        dict_len = len(dict_bin)\n",
    "        dicionario_size = struct.pack('!I', dict_len)\n",
    "        comp.write(dicionario_size)\n",
    "        comp.write(dict_bin)\n",
    "\n",
    "        #imagem\n",
    "        padding = 8 - len(matriz_codigos)%8\n",
    "        padding_bin = struct.pack('!I', padding)\n",
    "        comp.write(padding_bin)\n",
    "        matriz_codigos = matriz_codigos + ('0' * padding)\n",
    "        assert(len(matriz_codigos)%8 == 0)\n",
    "\n",
    "        enc = BitArray(bin='')\n",
    "        cnt = 0\n",
    "        while(cnt < len(matriz_codigos)):\n",
    "            enc = enc + BitArray(bin=matriz_codigos[cnt:cnt+8])\n",
    "            cnt += 8\n",
    "\n",
    "        comp.write(enc.bytes)\n",
    "        return 'compressed.txt'\n",
    "    \n",
    "def recupera_dados(nome_arquivo):\n",
    "    with open(nome_arquivo, 'rb') as comp:\n",
    "        oito_bytes = comp.read(8)\n",
    "\n",
    "        w_comp = struct.unpack('!I', oito_bytes[:4])[0]\n",
    "        h_comp = struct.unpack('!I', oito_bytes[4:])[0]\n",
    "\n",
    "        quatro_bytes = comp.read(4)\n",
    "        tam_dict = struct.unpack('!I', quatro_bytes)[0]\n",
    "\n",
    "        quatro_bytes = comp.read(tam_dict)\n",
    "        cod_dict = {int(k): v for k, v in json.loads(quatro_bytes).items()}\n",
    "\n",
    "        quatro_bytes = comp.read(4)\n",
    "        recpadding = struct.unpack('!I', quatro_bytes)[0]\n",
    "\n",
    "        img_binary = comp.read()\n",
    "        img_bitstr = BitArray(img_binary).bin[:-recpadding]\n",
    "    return h_comp, w_comp, cod_dict, img_bitstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Obtenção e especificação da imagem orginal\n",
    "Recebe o nome do arquivo da imagem e calcula as informações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = input(\"Entre o nome do arquivo de imagem: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = cv2.imread(infile,0)\n",
    "\n",
    "height, width =  img_original.shape\n",
    "size = height, width\n",
    "imprime_imagem(img_original, \"Imagem Original\")\n",
    "\n",
    "entropia_original = calcula_entropia(img_original)\n",
    "tamanho_imagem_bytes = entropia_original*height* width/8\n",
    "tam_arquivo_original = os.path.getsize(infile)\n",
    "print(\"Entropia imagem original: \", entropia_original)\n",
    "print(\"Tamanho da imagem em bytes: \", tamanho_imagem_bytes)\n",
    "print(\"Tamanho do arquivo da imagem em bytes: \", tam_arquivo_original, \"bytes \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Aplicação da codificação preditiva sem perda\n",
    "\n",
    "Este tipo de codificação explora a redundância interpixel, que explora a característica de que pixels vizinhos normalmente possuem alguma realção. O processo consiste na suposição do valor de cada pixel a partir do pixel vizinho e no registro da diferença entre o valor previsto e o valor real em uma matriz de erro.  No caso, a função f(x+1) = f(x) foi utilizada como função preditora. A vantagem de se aplicar este método é diminuir a entropia da imagem se a redundância interpixel da imagem for alta. Assumindo que pixels próximos são parecidos, os valores na matriz de erro serão baixos, gerando um número de tons de cinza distintos menor, pois os valores altos (como a diferença entre bordas) aparecem com menos frequência.\n",
    "\n",
    "A construção da matriz de erro e o cálculo da entropia são realizados abaixo. Se o valor da entropia for inferior à entropia da imagem original a codificação de Huffman será efetiva. Caso contrário, a imagem escolhida não é uma boa opção para este método. A taxa de compressão máxima considerando apenas a estrutura das imagens é calculada abaixo. Se a taxa for acima de 1 a entropia diminuiu, caso contrário a predição de erro não é eficiente para a imagem escolhida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_erro = predicao_erro(img_original, height, width)\n",
    "entropia_erro = calcula_entropia(img_pred_erro)\n",
    "imprime_imagem(img_pred_erro, \"Representação matriz de erro\")\n",
    "print(\"Entropia matriz de erro: \", entropia_erro, \"\\n\")\n",
    "print(\"Taxa de compressão máxima: \", entropia_original/entropia_erro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Aplicação da codificação de Huffman\n",
    "\n",
    "A codificação de Huffman utiliza a redundância de codificação para reduzir o tamanho dos códigos utilizados para representar níveis de cinza contidos na imagem. A imagem original possui tons de cinza que variam entre 0 e 255, sendo representados cada um por 8bits. A ideia é reduzir o código de um tom de cinza que tem probabilidade alta e utilizar uma sequência maior para os que aparecem pouco. \n",
    "\n",
    "O algoritmo consiste na criação de uma árvore em que os símbolos com menor probabilidade são incluídos antes e a árvore é construída de baixo para cima. No fim, o caminho na árvore da raiz ao símbolo te dá a codificação. Na implementação, uma lista foi utilizada como estrutura no lugar da árvore para realizar a ordenação das probabilidades, mas a ideian central do algoritmo original foi mantida.\n",
    "\n",
    "Este método só é eficiente quando a entropia é menor do que o número médio original de bits por pixels. Neste caso, a codificação preditiva foi aplicada anteriormente para diminuir a entropia e aumentar a eficiência desta codificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_codigos = codif_Huffman(img_pred_erro,height, width)\n",
    "#print(dicionario_codigos)\n",
    "\n",
    "matriz_codigos = \"\"\n",
    "for row in range(0, height):\n",
    "    for col in range(0, width):\n",
    "        matriz_codigos = matriz_codigos + dicionario_codigos[img_pred_erro[row][col]]\n",
    "\n",
    "print(\"Eficiência da codificação de Huffman: \", eficiencia_Huffman(matriz_codigos, entropia_erro, height, width), \"\\n\")\n",
    "        \n",
    "print(\"Subsituição dos códigos originais pela nova codificação: \\n\\n\",matriz_codigos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Armazenamaneto da imagem\n",
    "Os dados foram convertidos para bytes com auxílio da estrutura bitArray e do módulo Struct (que interpreta bytes como dados binários compactados), e foram armazenados em um arquivo de texto da seguinte forma:\n",
    "- largura (4 bytes)\n",
    "- altura (4 bytes)\n",
    "- dict_len: Número de bytes ocupados pelo dicionário de Huffman (4 bytes)\n",
    "- Dicionário de Huffman (dict_len bytes)\n",
    "- \"padding\" (4 bytes) (necessário para tornar a sequência da imagem um múltiplo de 8)\n",
    "- imagem com os novos códigos (restante do arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo = armazena_imagem(img_original, dicionario_codigos, matriz_codigos)\n",
    "print(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Recuperação da imagem armazenada\n",
    "Seguindo a ordem de armazenamento citada acima, a função recupera cada um dos dados em bytes e converte para o formato original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_height, r_width, cod_dict, img_cod = recupera_dados(nome_arquivo)\n",
    "print(r_height,r_width,\"\\n\\n\", cod_dict, \"\\n\\n\", img_cod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Decodificação do código de Huffman\n",
    "Uma vez que temos o dicionário dos códigos de Huffman e a sequência correspondente à matriz codificada, podemos agora realizar o inverso de Huffman, identificando cada código na sequência e substituindo cada posição na matriz de recuperação pelo símbolo original. A matriz resultante é a matriz de erro sem nehuma perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_dict_inv = {v: k for k, v in cod_dict.items()}\n",
    "imagem_recuperada = decod_Huffman(img_cod, cod_dict_inv, r_height, r_width)\n",
    "imprime_imagem(imagem_recuperada, \"Imagem de erro recuperada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Recuperação da imagem a partir da matriz de erro\n",
    "A partir da matriz de erro podemos recuperar a imagem aplicando o inverso da função preditiva aplicada no início e computando o erro. Neste passo também não temos perda de informação pois a primeira coluna manteve os valores originais da imagem e o erro não foi quantizado. O resultado desejado é uma matriz semelhante a imagem original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_recuperada = recupera_erro(imagem_recuperada, r_height, r_width)\n",
    "imprime_imagem(imagem_recuperada, \"Imagem final\")\n",
    "entropia_imagem_recuperada = calcula_entropia(imagem_recuperada)\n",
    "print(\"Entropia imagem recuperada: \", entropia_imagem_recuperada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Análise final\n",
    "A qualidade da compressão pode ser avaliada pelo erro médio quadrático (média da soma do quadrado das diferenças de cada ponto). No caso, como temos uma compressão sem perdas, o resultado do erro é sempre igual a zero.\n",
    "\n",
    "Quanto a taxa de compressão final obtida, observamos que em algumas imagens testadas o tamanho do arquivo da imagem era muito superior ao tamanho calculado a partir da entropia e das dimensões da imagem (e que a diferença variava muito de imagem para imagem). \n",
    "\n",
    "Assim, apresentamos duas taxas de compressão finais: a primeira é a taxa do tamanho dos arquivos original e final, que foi elevada para todos os testes realizados. A segunda é taxa entre o tamanho em bytes da imagem (calculada a partir da entropia) e do arquivo final obtido. Esta taxa se mostrou em todos os casos testados semelhante à taxa de compressão prevista da entropia da imagem original e da entropia obtida com os métodos aplicados. Assim, a segunda taxa é melhor para avaliar a eficiência dos métodos aplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imprime_imagem(img_original, \"Imagem original\")\n",
    "tam_arquivo_original = os.path.getsize(infile)\n",
    "print(\"Tamanho do arquivo da imagem original: \", tam_arquivo_original, \"bytes \\n\")\n",
    "print(\"Tamanho da imagem original em bytes: \", tamanho_imagem_bytes)\n",
    "\n",
    "imprime_imagem(imagem_recuperada, \"Imagem final\")\n",
    "tam_compr = os.path.getsize(nome_arquivo)\n",
    "print(\"Tamanho do arquivo armazenado: \", tam_compr, \"bytes \\n\\n\\n\")\n",
    "\n",
    "print(\"Taxa de compressão dos arquivos: \", tam_arquivo_original/tam_compr, \"\\n\")\n",
    "print(\"Taxa de compressão imagem original e arquivo final: \", tamanho_imagem_bytes/tam_compr, \"\\n\")\n",
    "print(\"Taxa de compressão máxima da entropia com os métodos aplicados: \", entropia_original/entropia_erro, \"\\n\")\n",
    "print(\"Eficiência da codificação de Huffman: \", eficiencia_Huffman(matriz_codigos, entropia_erro, height, width), \"\\n\")\n",
    "print(\"Erro médio quadrático: \", rmse(img_original, imagem_recuperada), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
